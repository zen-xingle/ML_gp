----------------------------------------

  Demo cigp 

----------------------------------------
---> module config
  dataset: {'name': 'TopOP_mfGent_v5', 'fidelity': ['low'], 'type': 'x_2_y', 'train_start_index': 0, 'train_sample': 8, 'eval_start_index': 0, 'eval_sample': 128, 'seed': None}
  lr: {'kernel': 0.1, 'optional_param': 0.1, 'noise': 0.1}
  kernel: {'K1': {'SE': {'exp_restrict': False, 'length_scale': 1.0, 'scale': 1.0}}}
  evaluate_method: ['mae', 'rmse', 'r2']
  optimizer: adam
  exp_restrict: False
  input_normalize: True
  output_normalize: True
  noise_init: 1.0
  res_cigp: None
---> training record
  epoch       	mae         	rmse        	r2          	time        
  1           	0.13148     	0.18433     	-32.46941   	0           
  10          	0.14220     	0.19357     	-74.25451   	0           
  100         	0.08899     	0.13848     	-7.02144    	0           
  300         	0.08371     	0.13307     	-5.02526    	0           
  500         	0.08253     	0.13185     	-4.50828    	0           
  1000        	0.08161     	0.13088     	-4.02513    	1           
---> try to load best state
              	0.08161     	0.13088     	-4.02513    	1                eval state : test_on_restore;
              	0.08161     	0.13088     	-4.02513    	1                eval state : test_on_last_epoch;
---> final result
              	0.08161     	0.13088     	-4.02513    	1                eval state : final;
---> end

----------------------------------------

  Demo hogp 

----------------------------------------
---> module config
  dataset: {'name': 'TopOP_mfGent_v5', 'fidelity': ['low'], 'type': 'x_2_y', 'train_start_index': 0, 'train_sample': 32, 'eval_start_index': 0, 'eval_sample': 128, 'seed': 0}
  lr: {'kernel': 0.1, 'optional_param': 0.1, 'noise': 0.1}
  kernel: {'K1': {'SE': {'exp_restrict': True, 'length_scale': 1.0, 'scale': 1.0}}, 'K2': {'SE': {'exp_restrict': True, 'length_scale': 1.0, 'scale': 1.0}}, 'K3': {'SE': {'exp_restrict': True, 'length_scale': 1.0, 'scale': 1.0}}}
  evaluate_method: ['mae', 'rmse', 'r2', 'gaussian_loss']
  optimizer: adam
  exp_restrict: False
  input_normalzie: True
  output_normalize: True
  noise_init: 100.0
  grid_config: {'grid_size': [-1, -1], 'type': 'fixed', 'dimension_map': 'identity'}
---> training record
  epoch       	mae         	r2          	rmse        	gaussian_loss      	time        
  1           	0.05768     	0.81142     	0.08539     	18.15626           	0           
  10          	0.04766     	0.88255     	0.07139     	-4.96192           	0           
  100         	0.04780     	0.84405     	0.07641     	14.72625           	0           
  300         	0.04783     	0.84366     	0.07670     	9.81767            	1           
  500         	0.04855     	0.83999     	0.07799     	3.96804            	2           
  1000        	0.04927     	0.82906     	0.07763     	12.68856           	4           
---> try to load best state
              	0.04927     	0.82906     	0.07763     	12.68856           	4                eval state : test_on_restore;
              	0.04927     	0.82906     	0.07763     	12.68856           	4                eval state : test_on_last_epoch;
---> final result
              	0.04927     	0.82906     	0.07763     	12.68856           	4                eval state : final;
---> end

